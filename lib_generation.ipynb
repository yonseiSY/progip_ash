{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_batch(data, batch, k):\n",
    "    '''\n",
    "    commpute lid score using data & batch with k-neighbors\n",
    "    return: a: computed LID score\n",
    "    '''\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    batch = np.asarray(batch, dtype=np.float32)\n",
    "\n",
    "    k = min(k, len(data)-1)\n",
    "    f = lambda v: - k / np.sum(np.log(v/v[-1]))\n",
    "    a = cdist(batch, data)\n",
    "    a = np.apply_along_axis(np.sort, axis=1, arr=a)[:,1:k+1]\n",
    "    a = np.apply_along_axis(f, axis=1, arr=a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28781b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_generate_labels(X_pos, X_neg):\n",
    "    \"\"\"\n",
    "    merge positve and nagative artifact and generate labels\n",
    "    return: X: merged samples, 2D ndarray\n",
    "             y: generated labels (0/1): 2D ndarray same size as X\n",
    "    \"\"\"\n",
    "    X_pos = np.asarray(X_pos, dtype=np.float32)\n",
    "    X_pos = X_pos.reshape((X_pos.shape[0], -1))\n",
    "\n",
    "    X_neg = np.asarray(X_neg, dtype=np.float32)\n",
    "    X_neg = X_neg.reshape((X_neg.shape[0], -1))\n",
    "\n",
    "    X = np.concatenate((X_pos, X_neg))\n",
    "    y = np.concatenate((np.ones(X_pos.shape[0]), np.zeros(X_neg.shape[0])))\n",
    "    y = y.reshape((X.shape[0], 1))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_estimator(model, num_classes, feature_list, train_loader):\n",
    "    \"\"\"\n",
    "    compute sample mean and precision (inverse of covariance)\n",
    "    return: sample_class_mean: list of class mean\n",
    "             precision: list of precisions\n",
    "    \"\"\"\n",
    "    import sklearn.covariance\n",
    "    \n",
    "    model.eval()\n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "    correct, total = 0, 0\n",
    "    num_output = len(feature_list)\n",
    "    num_sample_per_class = np.empty(num_classes)\n",
    "    num_sample_per_class.fill(0)\n",
    "    list_features = []\n",
    "    for i in range(num_output):\n",
    "        temp_list = []\n",
    "        for j in range(num_classes):\n",
    "            temp_list.append(0)\n",
    "        list_features.append(temp_list)\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        total += data.size(0)\n",
    "        data = data.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, out_features = model.feature_list(data)\n",
    "        \n",
    "        # get hidden features\n",
    "        for i in range(num_output):\n",
    "            out_features[i] = out_features[i].view(out_features[i].size(0), out_features[i].size(1), -1)\n",
    "            out_features[i] = torch.mean(out_features[i].data, 2)\n",
    "            \n",
    "        # compute the accuracy\n",
    "        pred = output.data.max(1)[1]\n",
    "        equal_flag = pred.eq(target.cuda()).cpu()\n",
    "        correct += equal_flag.sum()\n",
    "        \n",
    "        # construct the sample matrix\n",
    "        for i in range(data.size(0)):\n",
    "            label = target[i]\n",
    "            if num_sample_per_class[label] == 0:\n",
    "                out_count = 0\n",
    "                for out in out_features:\n",
    "                    list_features[out_count][label] = out[i].view(1, -1)\n",
    "                    out_count += 1\n",
    "            else:\n",
    "                out_count = 0\n",
    "                for out in out_features:\n",
    "                    list_features[out_count][label] \\\n",
    "                    = torch.cat((list_features[out_count][label], out[i].view(1, -1)), 0)\n",
    "                    out_count += 1                \n",
    "            num_sample_per_class[label] += 1\n",
    "            \n",
    "    sample_class_mean = []\n",
    "    out_count = 0\n",
    "    for num_feature in feature_list:\n",
    "        temp_list = torch.Tensor(num_classes, int(num_feature)).cuda()\n",
    "        for j in range(num_classes):\n",
    "            temp_list[j] = torch.mean(list_features[out_count][j], 0)\n",
    "        sample_class_mean.append(temp_list)\n",
    "        out_count += 1\n",
    "        \n",
    "    precision = []\n",
    "    for k in range(num_output):\n",
    "        X = 0\n",
    "        for i in range(num_classes):\n",
    "            if i == 0:\n",
    "                X = list_features[k][i] - sample_class_mean[k][i]\n",
    "            else:\n",
    "                X = torch.cat((X, list_features[k][i] - sample_class_mean[k][i]), 0)\n",
    "                \n",
    "        # find inverse            \n",
    "        group_lasso.fit(X.cpu().numpy())\n",
    "        temp_precision = group_lasso.precision_\n",
    "        temp_precision = torch.from_numpy(temp_precision).float().cuda()\n",
    "        precision.append(temp_precision)\n",
    "        \n",
    "    print('\\n Training Accuracy:({:.2f}%)\\n'.format(100. * correct / total))\n",
    "\n",
    "    return sample_class_mean, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Mahalanobis_score(model, test_loader, num_classes, outf, out_flag, std, sample_mean, precision, layer_index, magnitude):\n",
    "    '''\n",
    "    Compute the proposed Mahalanobis confidence score on input dataset\n",
    "    return: Mahalanobis score from layer_index\n",
    "    '''\n",
    "    model.eval()\n",
    "    Mahalanobis = []\n",
    "    \n",
    "    if out_flag == True:\n",
    "        temp_file_name = '%s/confidence_Ga%s_In.txt'%(outf, str(layer_index))\n",
    "    else:\n",
    "        temp_file_name = '%s/confidence_Ga%s_Out.txt'%(outf, str(layer_index))\n",
    "        \n",
    "    g = open(temp_file_name, 'w')\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        \n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data.requires_grad_()\n",
    "        \n",
    "        out_features = model.intermediate_forward(data, layer_index)\n",
    "        out_features = out_features.view(out_features.size(0), out_features.size(1), -1)\n",
    "        out_features = torch.mean(out_features, 2)\n",
    "        \n",
    "        # compute Mahalanobis score\n",
    "        gaussian_score = 0\n",
    "        for i in range(num_classes):\n",
    "            batch_sample_mean = sample_mean[layer_index][i]\n",
    "            zero_f = out_features.data - batch_sample_mean\n",
    "            term_gau = -0.5*torch.mm(torch.mm(zero_f, precision[layer_index]), zero_f.t()).diag()\n",
    "            if i == 0:\n",
    "                gaussian_score = term_gau.view(-1,1)\n",
    "            else:\n",
    "                gaussian_score = torch.cat((gaussian_score, term_gau.view(-1,1)), 1)\n",
    "        \n",
    "        # Input_processing\n",
    "        sample_pred = gaussian_score.max(1)[1]\n",
    "        batch_sample_mean = sample_mean[layer_index].index_select(0, sample_pred)\n",
    "        zero_f = out_features - batch_sample_mean\n",
    "        pure_gau = -0.5*torch.mm(torch.mm(zero_f, precision[layer_index]), zero_f.t()).diag()\n",
    "        loss = torch.mean(-pure_gau)\n",
    "        loss.backward()\n",
    "         \n",
    "        gradient =  torch.ge(data.grad.data, 0)\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "        \n",
    "        gradient.index_copy_(1, torch.LongTensor([0]).cuda(), gradient.index_select(1, torch.LongTensor([0]).cuda()) / std[0])\n",
    "        gradient.index_copy_(1, torch.LongTensor([1]).cuda(), gradient.index_select(1, torch.LongTensor([1]).cuda()) / std[1])\n",
    "        gradient.index_copy_(1, torch.LongTensor([2]).cuda(), gradient.index_select(1, torch.LongTensor([2]).cuda()) / std[2])\n",
    "            \n",
    "        tempInputs = torch.add(data.detach(), gradient, alpha=-magnitude)\n",
    " \n",
    "        with torch.no_grad():\n",
    "            noise_out_features = model.intermediate_forward(tempInputs, layer_index)\n",
    "            \n",
    "        noise_out_features = noise_out_features.view(noise_out_features.size(0), noise_out_features.size(1), -1)\n",
    "        noise_out_features = torch.mean(noise_out_features, 2)\n",
    "        noise_gaussian_score = 0\n",
    "        for i in range(num_classes):\n",
    "            batch_sample_mean = sample_mean[layer_index][i]\n",
    "            zero_f = noise_out_features.data - batch_sample_mean\n",
    "            term_gau = -0.5*torch.mm(torch.mm(zero_f, precision[layer_index]), zero_f.t()).diag()\n",
    "            if i == 0:\n",
    "                noise_gaussian_score = term_gau.view(-1,1)\n",
    "            else:\n",
    "                noise_gaussian_score = torch.cat((noise_gaussian_score, term_gau.view(-1,1)), 1)      \n",
    "\n",
    "        noise_gaussian_score, _ = torch.max(noise_gaussian_score, dim=1)\n",
    "        Mahalanobis.extend(noise_gaussian_score.cpu().numpy())\n",
    "        \n",
    "        for i in range(data.size(0)):\n",
    "            g.write(\"{}\\n\".format(noise_gaussian_score[i]))\n",
    "    g.close()\n",
    "\n",
    "    return Mahalanobis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2 (NGC 23.11/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
