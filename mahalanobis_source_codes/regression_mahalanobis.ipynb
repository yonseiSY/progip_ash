{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0881cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Oct 21 2018\n",
    "@author: Kimin Lee\n",
    "\"\"\"\n",
    "\n",
    "import import_ipynb\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import lib_regression\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d003cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(id_dataset='', ood_dataset='', file_path='', score=''):    \n",
    "    \n",
    "    # train and measure the performance of Mahalanobis detector\n",
    "    list_best_results, list_best_results_index = [], []\n",
    "    list_best_results_out, list_best_results_index_out = [], []\n",
    "    best_tnr, best_result, best_index = 0, 0, 0\n",
    "    \n",
    "    total_X, total_Y = lib_regression.load_characteristics(score, id_dataset, ood_dataset, file_path)\n",
    "    X_val, Y_val, X_test, Y_test = lib_regression.block_split(total_X, total_Y)\n",
    "        \n",
    "    X_train = np.concatenate((X_val[:500], X_val[1000:1500]))\n",
    "    Y_train = np.concatenate((Y_val[:500], Y_val[1000:1500]))\n",
    "    X_val_for_test = np.concatenate((X_val[500:1000], X_val[1500:]))\n",
    "    Y_val_for_test = np.concatenate((Y_val[500:1000], Y_val[1500:]))\n",
    "    \n",
    "    lr = LogisticRegressionCV(n_jobs=-1).fit(X_train, Y_train)\n",
    "    \n",
    "    # y_pred = lr.predict_proba(X_train)[:, 1]\n",
    "    # #print('training mse: {:.4f}'.format(np.mean(y_pred - Y_train)))\n",
    "    # y_pred = lr.predict_proba(X_val_for_test)[:, 1]\n",
    "    # #print('test mse: {:.4f}'.format(np.mean(y_pred - Y_val_for_test)))\n",
    "    \n",
    "    results = lib_regression.detection_performance(lr, X_val_for_test, Y_val_for_test, file_path)\n",
    "    \n",
    "    if best_tnr < results['TMP']['TNR']:\n",
    "        best_tnr = results['TMP']['TNR']\n",
    "        best_index = score\n",
    "        best_result = lib_regression.detection_performance(lr, X_test, Y_test, file_path)\n",
    "            \n",
    "    list_best_results_out.append(best_result)\n",
    "    list_best_results_index_out.append(best_index)\n",
    "    list_best_results.append(list_best_results_out)\n",
    "    list_best_results_index.append(list_best_results_index_out)\n",
    "        \n",
    "    # print the results\n",
    "    count_in = 0\n",
    "    mtypes = ['TNR', 'AUROC', 'DTACC', 'AUIN', 'AUOUT']\n",
    "\n",
    "    for in_list in list_best_results:\n",
    "        out_list = ['svhn']\n",
    "        count_out = 0\n",
    "        for results in in_list:\n",
    "            print('out_distribution: '+ out_list[count_out])\n",
    "            for mtype in mtypes:\n",
    "                print(' {mtype:6s}'.format(mtype=mtype), end='')\n",
    "            print('\\n{val:6.2f}'.format(val=100.*results['TMP']['TNR']), end='')\n",
    "            print(' {val:6.2f}'.format(val=100.*results['TMP']['AUROC']), end='')\n",
    "            print(' {val:6.2f}'.format(val=100.*results['TMP']['DTACC']), end='')\n",
    "            print(' {val:6.2f}'.format(val=100.*results['TMP']['AUIN']), end='')\n",
    "            print(' {val:6.2f}\\n'.format(val=100.*results['TMP']['AUOUT']), end='')\n",
    "            print('Input noise: ' + list_best_results_index[count_in][count_out])\n",
    "            print('')\n",
    "            count_out += 1\n",
    "        count_in += 1\n",
    "        \n",
    "    # 최종 AUROC, FPR(TNR 기반) 추출\n",
    "    final_auroc = best_result['TMP']['AUROC']\n",
    "    final_fpr = 1.0 - best_result['TMP']['TNR']\n",
    "    \n",
    "    return final_auroc, final_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_fi(id_dataset='', ood_dataset='', file_path='', score=''):    \n",
    "    \n",
    "    # train and measure the performance of Mahalanobis detector\n",
    "    list_best_results, list_best_results_index = [], []\n",
    "    list_best_results_out, list_best_results_index_out = [], []\n",
    "    best_tnr, best_result, best_index = 0, 0, 0\n",
    "    \n",
    "    total_X, total_Y = lib_regression.load_characteristics(score, id_dataset, ood_dataset, file_path)\n",
    "    X_val, Y_val, X_test, Y_test = lib_regression.block_split(total_X, total_Y)\n",
    "        \n",
    "    X_train = np.concatenate((X_val[:500], X_val[1000:1500]))\n",
    "    Y_train = np.concatenate((Y_val[:500], Y_val[1000:1500]))\n",
    "    X_val_for_test = np.concatenate((X_val[500:1000], X_val[1500:]))\n",
    "    Y_val_for_test = np.concatenate((Y_val[500:1000], Y_val[1500:]))\n",
    "    \n",
    "    lr = LogisticRegressionCV(n_jobs=-1).fit(X_train, Y_train)\n",
    "    \n",
    "    # y_pred = lr.predict_proba(X_train)[:, 1]\n",
    "    # #print('training mse: {:.4f}'.format(np.mean(y_pred - Y_train)))\n",
    "    # y_pred = lr.predict_proba(X_val_for_test)[:, 1]\n",
    "    # #print('test mse: {:.4f}'.format(np.mean(y_pred - Y_val_for_test)))\n",
    "    \n",
    "    results = lib_regression.detection_performance(lr, X_val_for_test, Y_val_for_test, file_path)\n",
    "    \n",
    "    if best_tnr < results['TMP']['TNR']:\n",
    "        best_tnr = results['TMP']['TNR']\n",
    "        best_index = score\n",
    "        best_result = lib_regression.detection_performance(lr, X_test, Y_test, file_path)\n",
    "            \n",
    "    list_best_results_out.append(best_result)\n",
    "    list_best_results_index_out.append(best_index)\n",
    "    list_best_results.append(list_best_results_out)\n",
    "    list_best_results_index.append(list_best_results_index_out)\n",
    "        \n",
    "    # print the results\n",
    "    count_in = 0\n",
    "    mtypes = ['TNR', 'AUROC', 'DTACC', 'AUIN', 'AUOUT']\n",
    "\n",
    "    for in_list in list_best_results:\n",
    "        out_list = ['svhn']\n",
    "        count_out = 0\n",
    "        for results in in_list:\n",
    "            print('out_distribution: '+ out_list[count_out])\n",
    "            for mtype in mtypes:\n",
    "                print(' {mtype:6s}'.format(mtype=mtype), end='')\n",
    "            print('\\n{val:6.2f}'.format(val=100.*results['TMP']['TNR']), end='')\n",
    "            print(' {val:6.2f}'.format(val=100.*results['TMP']['AUROC']), end='')\n",
    "            print(' {val:6.2f}'.format(val=100.*results['TMP']['DTACC']), end='')\n",
    "            print(' {val:6.2f}'.format(val=100.*results['TMP']['AUIN']), end='')\n",
    "            print(' {val:6.2f}\\n'.format(val=100.*results['TMP']['AUOUT']), end='')\n",
    "            print('Input noise: ' + list_best_results_index[count_in][count_out])\n",
    "            print('')\n",
    "            count_out += 1\n",
    "        count_in += 1\n",
    "        \n",
    "    # 최종 AUROC, FPR(TNR 기반) 추출\n",
    "    fi_final_auroc = best_result['TMP']['AUROC']\n",
    "    fi_final_fpr = 1.0 - best_result['TMP']['TNR']\n",
    "    \n",
    "    return fi_final_auroc, fi_final_fpr    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
