{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f8e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import torch\n",
    "import dataloader\n",
    "import generate_mahalanobis\n",
    "import regression_mahalanobis\n",
    "import generate_odin\n",
    "import calmetric\n",
    "from models.resnet import ResNet34, ResNet18\n",
    "from models.densenet import DenseNet3\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02b3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d661ba73",
   "metadata": {},
   "source": [
    "## No Fault Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c40474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_datasets = ['cifar10', 'cifar100']\n",
    "# ood_dataset = 'svhn'\n",
    "# model_names = ['resnet34', 'densenet3']\n",
    "# batch_size = 128\n",
    "# magnitude = 0.0014\n",
    "# temperature = 1000\n",
    "\n",
    "# for id_dataset in id_datasets:\n",
    "#     if id_dataset == 'cifar10':\n",
    "#         num_classes = 10\n",
    "#     elif id_dataset == 'cifar100':\n",
    "#         num_classes = 100\n",
    "        \n",
    "#     for model_name in model_names:\n",
    "#         if model_name == 'resnet34':\n",
    "#             model = ResNet34(num_c=num_classes).to(device)\n",
    "#         elif model_name == 'densenet3':\n",
    "#             model = DenseNet3(100, num_classes, growth_rate=12).to(device)\n",
    "            \n",
    "#         model_path = f'./pretrained/{model_name}_{id_dataset}.pth'\n",
    "#         model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "#         model.eval()\n",
    "        \n",
    "#         mean, std = dataloader.get_mean_std(id_dataset)    \n",
    "        \n",
    "#         id_trainloader, id_testloader = dataloader.get_imageloader(id_dataset, batch_size, mean, std)    \n",
    "#         _, out_testloader = dataloader.get_imageloader(ood_dataset, batch_size, mean, std)    \n",
    "        \n",
    "#         ##### ODIN #####\n",
    "        \n",
    "#         file_path = f'./softmax_scores/{model_name}_{id_dataset}'\n",
    "        \n",
    "#         if not os.path.exists(file_path):\n",
    "#             os.makedirs(file_path)\n",
    "            \n",
    "#         generate_odin.odin(model, id_testloader, out_testloader, magnitude, temperature, std, file_path)\n",
    "#         calmetric.metric(model_name, id_dataset, ood_dataset, file_path)\n",
    "        \n",
    "#         ##### Mahalanobis #####\n",
    "            \n",
    "#         file_path = f'./output/{model_name}_{id_dataset}'\n",
    "        \n",
    "#         if not os.path.exists(file_path):\n",
    "#             os.makedirs(file_path)\n",
    "        \n",
    "#         # generate_mahalanobis.mahalanobis(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path)\n",
    "#         # regression_mahalanobis.regression(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae676c",
   "metadata": {},
   "source": [
    "## Fault Injection - ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb1b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import fault_injector as fi\n",
    "# import PytorchFS.FS as FS\n",
    "\n",
    "# id_datasets = ['cifar10']\n",
    "# ood_dataset = 'svhn'\n",
    "# model_names = ['resnet34']\n",
    "# batch_size = 128\n",
    "# magnitude = 0.0014\n",
    "# temperature = 1000\n",
    "# ash_method = 'ash_p@90'\n",
    "\n",
    "# flip_pos = ''\n",
    "\n",
    "# first_forward_fi = True\n",
    "# backward_fi = True\n",
    "# second_forward_fi = True\n",
    "\n",
    "# single_flip = True\n",
    "# multi_flip = False\n",
    "# burst_flip = False\n",
    "\n",
    "# if single_flip:\n",
    "#     flip_pos += '_single'\n",
    "# elif multi_flip:\n",
    "#     flip_pos += '_multi'    \n",
    "# elif burst_flip:\n",
    "#     flip_pos += '_burst'\n",
    "\n",
    "# if first_forward_fi:\n",
    "#     flip_pos += '_ff'\n",
    "# if backward_fi:\n",
    "#     flip_pos += '_b'\n",
    "# if second_forward_fi:\n",
    "#     flip_pos += '_sf'    \n",
    "\n",
    "# for id_dataset in id_datasets:\n",
    "#     if id_dataset == 'cifar10':\n",
    "#         num_classes = 10\n",
    "#     elif id_dataset == 'cifar100':\n",
    "#         num_classes = 100\n",
    "        \n",
    "#     for model_name in model_names:\n",
    "#         if model_name == 'resnet34':\n",
    "#             model = ResNet34(num_c=num_classes).to(device)\n",
    "#         elif model_name == 'densenet3':\n",
    "#             model = DenseNet3(100, num_classes, growth_rate=12).to(device)\n",
    "            \n",
    "#         model_path = f'./pretrained/{model_name}_{id_dataset}.pth'\n",
    "#         model.load_state_dict(torch.load(model_path))\n",
    "#         model.eval()\n",
    "        \n",
    "#         fs = FS.FS()\n",
    "#         fs.setLayerInfo(model)\n",
    "        \n",
    "#         mean, std = dataloader.get_mean_std(id_dataset)    \n",
    "        \n",
    "#         id_trainloader, id_testloader = dataloader.get_imageloader(id_dataset, batch_size, mean, std)    \n",
    "#         _, out_testloader = dataloader.get_imageloader(ood_dataset, batch_size, mean, std)    \n",
    "        \n",
    "#         ##### ODIN #####\n",
    "        \n",
    "#         file_path = f'./softmax_scores/{model_name}_{id_dataset}'\n",
    "        \n",
    "#         if not os.path.exists(file_path):\n",
    "#             os.makedirs(file_path)\n",
    "            \n",
    "#         generate_odin.odin(model, id_testloader, out_testloader, magnitude, temperature, std, file_path)\n",
    "\n",
    "#         # CSV 파일 생성 및 헤더 작성 \n",
    "#         results_file = f'{file_path}/fi_results_{model_name}_{id_dataset}{flip_pos}.csv' \n",
    "\n",
    "#         with open(results_file, 'w', newline='') as csvfile: \n",
    "#             csv_writer = csv.writer(csvfile) \n",
    "#             if single_flip:\n",
    "#                 csv_writer.writerow(['layer_name', 'bit_position', 'auroc', 'fpr', 'auroc_fi', 'fpr_fi'])  \n",
    "#             elif multi_flip:\n",
    "#                 csv_writer.writerow(['layer_name', 'num_flips', 'bits', 'auroc', 'fpr', 'auroc_fi', 'fpr_fi'])                  \n",
    "#             elif burst_flip:\n",
    "#                 csv_writer.writerow(['layer_name', 'num_flips', 'start_bit', 'auroc', 'fpr', 'auroc_fi', 'fpr_fi'])                                  \n",
    "        \n",
    "#         # 컨볼루션 레이어와 FC 레이어 추출\n",
    "#         # layer_names = fi.get_layer_name(model)\n",
    "#         all_module_names = fs.getModuleNameList(model)\n",
    "#         layer_names = []\n",
    "        \n",
    "#         for name in all_module_names:\n",
    "#             if any(keyword.lower() in name.lower() for keyword in ['conv', 'fc', 'linear']):\n",
    "#                 layer_names.append(name)\n",
    "        \n",
    "#         # 각 컨볼루션 레이어 테스트 \n",
    "#         for layer_idx, layer_name in enumerate(layer_names): \n",
    "#             if 'fc' in layer_name or 'linear' in layer_name:\n",
    "#                 if id_dataset == 'cifar10':\n",
    "#                     num_flips = 1\n",
    "#                 elif id_dataset == 'cifar100':\n",
    "#                     num_flips = 10\n",
    "#             else:\n",
    "#                 if single_flip:\n",
    "#                     num_flips = 100\n",
    "#                 else:\n",
    "#                     num_flips = 100\n",
    "                \n",
    "#             print(f\"Testing layer {layer_idx+1}/{len(layer_names)}: {layer_name}\")  \n",
    "            \n",
    "#             layer_results = []  \n",
    "            \n",
    "#             # 각 비트 위치별 테스트\n",
    "#             if single_flip:\n",
    "#                 bit_position = 30\n",
    "#                 bit_positions = [bit_position]\n",
    "#                 print(f\"  Testing bit position: {bit_position}\")\n",
    "                    \n",
    "#                 generate_odin.odin_fi_ash(model, id_testloader, out_testloader, magnitude, temperature, std, file_path, \n",
    "#                                     first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi,\n",
    "#                                     bit_lists=bit_positions, flip_ratio=num_flips, layer_name=layer_name, fs=fs, ash_method=ash_method)\n",
    "                    \n",
    "#                 auroc, fpr, fi_auroc, fi_fpr = calmetric.metric_ash(model_name, id_dataset, ood_dataset, file_path)\n",
    "\n",
    "#                 generate_odin.odin_fi(model, id_testloader, out_testloader, magnitude, temperature, std, file_path, \n",
    "#                                     first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi,\n",
    "#                                     bit_lists=bit_positions, flip_ratio=num_flips, layer_name=layer_name, fs=fs)\n",
    "                    \n",
    "#                 auroc, fpr, fi_auroc, fi_fpr = calmetric.metric(model_name, id_dataset, ood_dataset, file_path)\n",
    "                    \n",
    "#                 # 결과를 CSV에 저장 \n",
    "#                 with open(results_file, 'a', newline='') as csvfile: \n",
    "#                     csv_writer = csv.writer(csvfile) \n",
    "#                     csv_writer.writerow([layer_name, bit_position, auroc, fpr, fi_auroc, fi_fpr])\n",
    "#             elif multi_flip:\n",
    "#                 # 1) 직접 지정한 burst 위치 리스트들\n",
    "#                 bit_positions = [[10, 30], [10, 20, 30]]\n",
    "\n",
    "#                 for bit_position in bit_positions:\n",
    "#                     generate_odin.odin_fi_ash(model, id_testloader, out_testloader, magnitude, temperature, std, file_path,\n",
    "#                                           first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi,\n",
    "#                                           bit_lists=bit_position, flip_ratio=num_flips, layer_name=layer_name, fs=fs, ash_method=ash_method)\n",
    "\n",
    "#                     # 4) 결과 측정\n",
    "#                     auroc, fpr, fi_auroc, fi_fpr = calmetric.metric_ash(model_name, id_dataset, ood_dataset, file_path)\n",
    "\n",
    "#                     generate_odin.odin_fi(model, id_testloader, out_testloader, magnitude, temperature, std, file_path,\n",
    "#                                           first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi,\n",
    "#                                           bit_lists=bit_position, flip_ratio=num_flips, layer_name=layer_name, fs=fs)\n",
    "\n",
    "#                     auroc, fpr, fi_auroc, fi_fpr = calmetric.metric(model_name, id_dataset, ood_dataset, file_path)\n",
    "                    \n",
    "#                     with open(results_file, 'a', newline='') as csvfile:\n",
    "#                         csv.writer(csvfile).writerow([layer_name, 2, bit_position, auroc, fpr, fi_auroc, fi_fpr])\n",
    "#             elif burst_flip:\n",
    "#                 # 1) 직접 지정한 burst 위치 리스트들\n",
    "#                 bit_positions = [[30, 31], [27, 28, 29, 30]]\n",
    "\n",
    "#                 for bit_position in bit_positions:\n",
    "#                     generate_odin.odin_fi_ash(model, id_testloader, out_testloader, magnitude, temperature, std, file_path,\n",
    "#                                           first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi,\n",
    "#                                           bit_lists=bit_position, flip_ratio=num_flips, layer_name=layer_name, fs=fs, ash_method=ash_method)\n",
    "\n",
    "#                     # 4) 결과 측정\n",
    "#                     auroc, fpr, fi_auroc, fi_fpr = calmetric.metric_ash(model_name, id_dataset, ood_dataset, file_path)\n",
    "\n",
    "#                     generate_odin.odin_fi(model, id_testloader, out_testloader, magnitude, temperature, std, file_path,\n",
    "#                                           first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi,\n",
    "#                                           bit_lists=bit_position, flip_ratio=num_flips, layer_name=layer_name, fs=fs)\n",
    "\n",
    "#                     auroc, fpr, fi_auroc, fi_fpr = calmetric.metric(model_name, id_dataset, ood_dataset, file_path)\n",
    "\n",
    "#                     # 5) CSV에 기록\n",
    "#                     with open(results_file, 'a', newline='') as csvfile:\n",
    "#                         csv.writer(csvfile).writerow([layer_name, len(bit_position), bit_position[0], auroc, fpr, fi_auroc, fi_fpr])    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281ba07",
   "metadata": {},
   "source": [
    "## Fault Injection - Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a344e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples: 10000\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(100.00%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 86.60  97.23  92.33  97.58  96.00\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 1/34: conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(90.53%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.11  50.75  51.97  49.88  50.81\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(90.58%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.62  62.80  68.56  64.23  56.22\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 2/34: layer1.0.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.42%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  6.03  66.44  64.38  64.97  60.55\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.47%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.60  64.97  63.03  63.32  59.28\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 3/34: layer1.0.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(76.60%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.78  65.96  63.99  63.93  60.23\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(76.55%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.44  62.43  61.66  59.42  58.42\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 4/34: layer1.1.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.91%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.09  62.73  61.47  60.73  57.70\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(83.44%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.68  63.22  62.09  60.06  58.73\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 5/34: layer1.1.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(76.04%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.73  64.82  62.83  62.11  59.50\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(76.14%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  4.82  62.69  61.37  62.21  57.18\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 6/34: layer1.2.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(79.22%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.71  62.42  61.39  59.12  58.29\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(79.30%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  5.53  62.57  61.63  59.23  58.11\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 7/34: layer1.2.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(78.13%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  6.61  66.00  62.71  68.72  60.13\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(78.43%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  6.00  64.26  62.19  62.67  58.82\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 8/34: layer2.0.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.49%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.74  95.21  90.35  94.52  93.00\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.25%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.80  95.16  90.16  94.50  92.98\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 9/34: layer2.0.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.17%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.77  95.18  90.26  94.65  92.84\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(81.92%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.63  95.20  90.23  94.60  93.00\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 10/34: layer2.1.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.75%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.17  95.36  90.49  95.47  92.68\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.80%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.30  95.19  90.25  94.61  92.96\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 11/34: layer2.1.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(81.30%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.29  94.92  89.88  94.20  92.72\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(81.51%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.74  95.20  90.31  94.55  92.99\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 12/34: layer2.2.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(68.36%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.08  95.12  90.14  94.49  92.81\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(68.44%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.63  95.18  90.26  94.44  93.00\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 13/34: layer2.2.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.82%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.68  95.19  90.32  94.52  92.97\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.86%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.58  95.14  90.25  94.67  92.69\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 14/34: layer2.3.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(89.10%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.51  95.14  90.25  94.42  92.96\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(89.24%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.88  95.21  90.29  94.49  93.01\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 15/34: layer2.3.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(77.66%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.68  95.16  90.29  94.45  92.96\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(77.65%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.92  95.14  90.14  94.64  92.87\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 16/34: layer3.0.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.09%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.00  95.27  90.03  94.80  93.32\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.09%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.03  95.27  90.04  94.81  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 17/34: layer3.0.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.30%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.68  95.26  90.23  94.60  93.39\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.84%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.56  95.19  90.09  94.53  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 18/34: layer3.1.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(89.76%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.07  95.25  90.10  94.78  93.33\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(90.01%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.89  95.25  90.17  94.64  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 19/34: layer3.1.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(83.41%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.06  95.18  90.11  94.53  93.31\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(83.23%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.24  95.28  90.05  94.79  93.36\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 20/34: layer3.2.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(84.85%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.73  95.16  90.06  94.51  93.30\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(84.62%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.03  95.28  90.13  94.82  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 21/34: layer3.2.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(87.27%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.10  95.28  90.14  94.81  93.27\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(86.98%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.34  95.12  89.92  94.50  93.07\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 22/34: layer3.3.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(88.93%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.24  95.27  90.11  94.81  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(88.89%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.26  95.03  89.77  94.45  93.15\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 23/34: layer3.3.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.68%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.14  95.23  90.05  94.62  93.33\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(80.81%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.29  95.25  90.10  94.67  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 24/34: layer3.4.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(75.64%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.14  95.27  90.12  94.84  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(75.55%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.17  95.22  90.11  94.58  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 25/34: layer3.4.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(90.80%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.19  95.12  89.86  94.53  93.15\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(90.97%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.42  95.15  90.00  94.61  93.10\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 26/34: layer3.5.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(79.07%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.34  95.21  90.08  94.56  93.32\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(79.18%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.96  95.24  90.03  94.75  93.34\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 27/34: layer3.5.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(91.10%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 76.90  95.25  90.04  94.79  93.32\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(90.78%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 77.24  95.28  90.08  94.83  93.35\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 28/34: layer4.0.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(84.65%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 78.78  95.29  90.15  94.67  93.61\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(84.89%)\n",
      "\n",
      "get Mahalanobis scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 79.00  95.28  90.11  94.68  93.60\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 29/34: layer4.0.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(76.96%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 79.51  95.26  90.16  94.65  93.59\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(77.02%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 78.80  95.30  90.15  94.71  93.61\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 30/34: layer4.1.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(83.91%)\n",
      "\n",
      "get Mahalanobis scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 79.34  95.35  90.21  94.78  93.67\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(84.04%)\n",
      "\n",
      "get Mahalanobis scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 79.24  95.34  90.16  94.93  93.63\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 31/34: layer4.1.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(83.33%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 79.14  95.32  90.14  94.73  93.64\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(83.36%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 78.96  95.30  90.21  94.68  93.63\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 32/34: layer4.2.conv1\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.80%)\n",
      "\n",
      "get Mahalanobis scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 78.82  95.30  90.18  94.61  93.58\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(82.64%)\n",
      "\n",
      "get Mahalanobis scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soyeong\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 78.78  95.26  90.12  94.52  93.54\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 33/34: layer4.2.conv2\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(81.58%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 79.20  95.32  90.16  94.87  93.61\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(81.23%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 78.91  95.33  90.11  94.89  93.62\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "Testing layer 34/34: linear\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(99.89%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 86.60  97.23  92.33  97.58  96.00\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n",
      "get sample mean and covariance\n",
      "\n",
      " Training Accuracy:(99.87%)\n",
      "\n",
      "get Mahalanobis scores\n",
      "out_distribution: svhn\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 86.60  97.23  92.33  97.58  96.00\n",
      "Input noise: Mahalanobis_0.0014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import fault_injector as fi\n",
    "import PytorchFS.FS as FS\n",
    "\n",
    "id_datasets = ['cifar10']\n",
    "ood_dataset = 'svhn'\n",
    "model_names = ['resnet34']\n",
    "batch_size = 128\n",
    "magnitude = 0.0014\n",
    "temperature = 1000\n",
    "ash_method = 'ash_p@90'\n",
    "\n",
    "flip_pos = ''\n",
    "\n",
    "first_forward_fi = True\n",
    "backward_fi = True\n",
    "second_forward_fi = True\n",
    "\n",
    "single_flip = False\n",
    "multi_flip = True\n",
    "burst_flip = False\n",
    "\n",
    "if single_flip:\n",
    "    flip_pos += '_single'\n",
    "elif multi_flip:\n",
    "    flip_pos += '_multi'    \n",
    "elif burst_flip:\n",
    "    flip_pos += '_burst'\n",
    "\n",
    "if first_forward_fi:\n",
    "    flip_pos += '_ff'\n",
    "if backward_fi:\n",
    "    flip_pos += '_b'\n",
    "if second_forward_fi:\n",
    "    flip_pos += '_sf'    \n",
    "\n",
    "for id_dataset in id_datasets:\n",
    "    if id_dataset == 'cifar10':\n",
    "        num_classes = 10\n",
    "    elif id_dataset == 'cifar100':\n",
    "        num_classes = 100\n",
    "        \n",
    "    for model_name in model_names:\n",
    "        if model_name == 'resnet34':\n",
    "            model = ResNet34(num_c=num_classes).to(device)\n",
    "        elif model_name == 'densenet3':\n",
    "            model = DenseNet3(100, num_classes, growth_rate=12).to(device)\n",
    "            \n",
    "        model_path = f'./pretrained/{model_name}_{id_dataset}.pth'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        \n",
    "        fs = FS.FS()\n",
    "        fs.setLayerInfo(model)\n",
    "        \n",
    "        mean, std = dataloader.get_mean_std(id_dataset)    \n",
    "        \n",
    "        id_trainloader, id_testloader = dataloader.get_imageloader(id_dataset, batch_size, mean, std)    \n",
    "        _, out_testloader = dataloader.get_imageloader(ood_dataset, batch_size, mean, std)    \n",
    "        \n",
    "        ##### Mahalanobis #####\n",
    "        \n",
    "        file_path = f'./output/{model_name}_{id_dataset}'\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            os.makedirs(file_path)\n",
    "            \n",
    "        generate_mahalanobis.mahalanobis(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path)\n",
    "        auroc, fpr = regression_mahalanobis.regression(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}')\n",
    "\n",
    "        # CSV 파일 생성 및 헤더 작성 \n",
    "        results_file = f'{file_path}/fi_results_{model_name}_{id_dataset}{flip_pos}.csv' \n",
    "\n",
    "        with open(results_file, 'w', newline='') as csvfile: \n",
    "            csv_writer = csv.writer(csvfile) \n",
    "            if single_flip:\n",
    "                csv_writer.writerow(['layer_name', 'bit_position', 'auroc', 'fpr', 'auroc_fi', 'fpr_fi'])  \n",
    "            elif multi_flip:\n",
    "                csv_writer.writerow(['layer_name', 'num_flips', 'bits', 'auroc', 'fpr', 'auroc_fi', 'fpr_fi'])                  \n",
    "            elif burst_flip:\n",
    "                csv_writer.writerow(['layer_name', 'num_flips', 'start_bit', 'auroc', 'fpr', 'auroc_fi', 'fpr_fi'])                                  \n",
    "        \n",
    "        # 컨볼루션 레이어와 FC 레이어 추출\n",
    "        # layer_names = fi.get_layer_name(model)\n",
    "        all_module_names = fs.getModuleNameList(model)\n",
    "        layer_names = []\n",
    "        \n",
    "        for name in all_module_names:\n",
    "            if any(keyword.lower() in name.lower() for keyword in ['conv', 'fc', 'linear']):\n",
    "                layer_names.append(name)\n",
    "        \n",
    "        # 각 컨볼루션 레이어 테스트 \n",
    "        for layer_idx, layer_name in enumerate(layer_names): \n",
    "            if 'fc' in layer_name or 'linear' in layer_name:\n",
    "                if id_dataset == 'cifar10':\n",
    "                    num_flips = 1\n",
    "                elif id_dataset == 'cifar100':\n",
    "                    num_flips = 10\n",
    "            else:\n",
    "                if single_flip:\n",
    "                    num_flips = 100\n",
    "                else:\n",
    "                    num_flips = 100\n",
    "                \n",
    "            print(f\"Testing layer {layer_idx+1}/{len(layer_names)}: {layer_name}\")  \n",
    "            \n",
    "            layer_results = []  \n",
    "            \n",
    "            # 각 비트 위치별 테스트\n",
    "            if single_flip:\n",
    "                bit_position = 30\n",
    "                bit_positions = [bit_position]\n",
    "                print(f\"  Testing bit position: {bit_position}\")\n",
    "                    \n",
    "                generate_mahalanobis.mahalanobis_fi(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path,\n",
    "                                                    first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi, \n",
    "                                                    bit_lists=bit_positions, flip_ratio=num_flips, layer_name=layer_name, fs=fs)\n",
    "                \n",
    "                fi_auroc, fi_fpr = regression_mahalanobis.regression_fi(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}')\n",
    "                \n",
    "                # generate_mahalanobis.mahalanobis_fi_ash(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path,\n",
    "                #                                     first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi, \n",
    "                #                                     bit_lists=bit_positions, flip_ratio=num_flips, layer_name=layer_name, fs=fs, ash_method=ash_method)\n",
    "                \n",
    "                # fi_auroc, fi_fpr = regression_mahalanobis.regression_fi_ash(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}')                \n",
    "                    \n",
    "                # 결과를 CSV에 저장 \n",
    "                with open(results_file, 'a', newline='') as csvfile: \n",
    "                    csv_writer = csv.writer(csvfile) \n",
    "                    csv_writer.writerow([layer_name, bit_position, auroc, fpr, fi_auroc, fi_fpr])\n",
    "            elif multi_flip:\n",
    "                # 1) 직접 지정한 burst 위치 리스트들\n",
    "                bit_positions = [[10, 30], [10, 20, 30]]\n",
    "\n",
    "                for bit_position in bit_positions:\n",
    "                    # generate_mahalanobis.mahalanobis_fi(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path,\n",
    "                    #                                     first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi, \n",
    "                    #                                     bit_lists=bit_position, flip_ratio=num_flips, layer_name=layer_name, fs=fs)\n",
    "                    \n",
    "                    # fi_auroc, fi_fpr = regression_mahalanobis.regression_fi(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}')\n",
    "                    \n",
    "                    generate_mahalanobis.mahalanobis_fi_ash(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path,\n",
    "                                                        first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi, \n",
    "                                                        bit_lists=bit_position, flip_ratio=num_flips, layer_name=layer_name, fs=fs, ash_method=ash_method)\n",
    "                    \n",
    "                    fi_auroc, fi_fpr = regression_mahalanobis.regression_fi_ash(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}')                     \n",
    "                    \n",
    "                    with open(results_file, 'a', newline='') as csvfile:\n",
    "                        csv.writer(csvfile).writerow([layer_name, len(bit_position), bit_position, auroc, fpr, fi_auroc, fi_fpr])\n",
    "            elif burst_flip:\n",
    "                # 1) 직접 지정한 burst 위치 리스트들\n",
    "                bit_positions = [[30, 31], [27, 28, 29, 30]]\n",
    "\n",
    "                for bit_position in bit_positions:\n",
    "                    generate_mahalanobis.mahalanobis_fi(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path,\n",
    "                                                        first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi, \n",
    "                                                        bit_lists=bit_position, flip_ratio=num_flips, layer_name=layer_name, fs=fs)\n",
    "                    \n",
    "                    fi_auroc, fi_fpr = regression_mahalanobis.regression_fi(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}')\n",
    "\n",
    "                    # generate_mahalanobis.mahalanobis_fi_ash(model, id_trainloader, id_testloader, out_testloader, num_classes, magnitude, std, file_path,\n",
    "                    #                                     first_forward_fi=first_forward_fi, backward_fi=backward_fi, second_forward_fi=second_forward_fi, \n",
    "                    #                                     bit_lists=bit_positions, flip_ratio=num_flips, layer_name=layer_name, fs=fs, ash_method=ash_method)\n",
    "                    \n",
    "                    # fi_auroc, fi_fpr = regression_mahalanobis.regression_fi_ash(id_dataset, ood_dataset, file_path, score=f'Mahalanobis_{str(magnitude)}') \n",
    "                        \n",
    "                    # 5) CSV에 기록\n",
    "                    with open(results_file, 'a', newline='') as csvfile:\n",
    "                        csv.writer(csvfile).writerow([layer_name, len(bit_position), bit_position[0], auroc, fpr, fi_auroc, fi_fpr])      \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
