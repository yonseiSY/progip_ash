{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ash import get_score\n",
    "from datasets.dataset_factory import build_dataset, get_num_classes\n",
    "from models.model_factory import build_model\n",
    "from utils.metrics import compute_in, compute_traditional_ood\n",
    "from utils.utils import is_debug_session, load_config_yml, set_deterministic\n",
    "\n",
    "\n",
    "def eval_id_dataset(model, transform, dataset_name, output_dir, batch_size, scoring_method, use_gpu, use_tqdm):\n",
    "    print(f'Processing {dataset_name} dataset.')\n",
    "    dataset = build_dataset(dataset_name, transform, train=False)\n",
    "    g, seed_worker = set_deterministic()\n",
    "\n",
    "    # setup dataset\n",
    "    kwargs = {}\n",
    "    if torch.cuda.is_available() and not is_debug_session():\n",
    "        kwargs = {'num_workers': 5, 'pin_memory': True, 'generator': g, 'worker_init_fn': seed_worker}\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if use_tqdm:\n",
    "            progress_bar = tqdm(total=len(dataloader))\n",
    "\n",
    "        f1 = open(os.path.join(output_dir, \"in_scores.txt\"), 'w')\n",
    "        g1 = open(os.path.join(output_dir, \"in_labels.txt\"), 'w')\n",
    "        for i, samples in enumerate(dataloader):\n",
    "            images = samples[0]\n",
    "            labels = samples[1]\n",
    "\n",
    "            # Create non_blocking tensors for distributed training\n",
    "            if use_gpu:\n",
    "                images = images.cuda(non_blocking=True)\n",
    "                labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "            logits = model(images)\n",
    "            outputs = F.softmax(logits, dim=1)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            preds = np.argmax(outputs, axis=1)\n",
    "            confs = np.max(outputs, axis=1)\n",
    "\n",
    "            for k in range(preds.shape[0]):\n",
    "                g1.write(\"{} {} {}\\n\".format(labels[k], preds[k], confs[k]))\n",
    "\n",
    "            scores = get_score(logits, scoring_method)\n",
    "            for score in scores:\n",
    "                f1.write(\"{}\\n\".format(score))\n",
    "\n",
    "            if use_tqdm:\n",
    "                progress_bar.update()\n",
    "        f1.close()\n",
    "        g1.close()\n",
    "\n",
    "        if use_tqdm:\n",
    "            progress_bar.close()\n",
    "\n",
    "\n",
    "def eval_ood_dataset(model, transform, dataset_name, output_dir, batch_size, scoring_method, use_gpu, use_tqdm):\n",
    "    print(f'Processing {dataset_name} dataset.')\n",
    "    dataset = build_dataset(dataset_name, transform, train=False)\n",
    "    g, seed_worker = set_deterministic()\n",
    "\n",
    "    kwargs = {}\n",
    "    if torch.cuda.is_available() and not is_debug_session():\n",
    "        kwargs = {'num_workers': 5, 'pin_memory': True, 'generator': g, 'worker_init_fn': seed_worker}\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if use_tqdm:\n",
    "            progress_bar = tqdm(total=len(dataloader))\n",
    "\n",
    "        f1 = open(os.path.join(output_dir, f\"{dataset_name}.txt\"), 'w')\n",
    "        for i, samples in enumerate(dataloader):\n",
    "            images = samples[0]\n",
    "\n",
    "            # Create non_blocking tensors for distributed training\n",
    "            if use_gpu:\n",
    "                images = images.cuda(non_blocking=True)\n",
    "\n",
    "            logits = model(images)\n",
    "            scores = get_score(logits, scoring_method)\n",
    "            for score in scores:\n",
    "                f1.write(\"{}\\n\".format(score))\n",
    "\n",
    "            if use_tqdm:\n",
    "                progress_bar.update()\n",
    "        f1.close()\n",
    "\n",
    "        if use_tqdm:\n",
    "            progress_bar.close()\n",
    "\n",
    "\n",
    "def ood_eval(config, use_gpu, use_tqdm):\n",
    "    num_classes = get_num_classes(config['id_dataset'])\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    now = str(datetime.now())\n",
    "    output_dir = os.path.join(base_dir, 'output', now)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # construct the model\n",
    "    model, transform = build_model(config['model_name'], num_classes=num_classes)\n",
    "    if config['train_restore_file']:\n",
    "        checkpoint = os.path.join(os.getenv('MODELS'), config['train_restore_file'])\n",
    "        checkpoint = torch.load(checkpoint, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint)\n",
    "    else:\n",
    "        print('Warning: train_restore_file config not specified')\n",
    "    model.eval()\n",
    "\n",
    "    # apply ash\n",
    "    setattr(model, 'ash_method', config['method'])\n",
    "\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    eval_id_dataset(model, transform, config['id_dataset'], output_dir, config['batch_size'], config['scoring_method'], use_gpu, use_tqdm)\n",
    "    for ood_dataset in config['ood_datasets']:\n",
    "        eval_ood_dataset(model, transform, ood_dataset, output_dir, config['batch_size'], config['scoring_method'], use_gpu, use_tqdm)\n",
    "\n",
    "    name = f\"{config['method']} - {config['scoring_method']} - {config['id_dataset']}\"\n",
    "    print(name)\n",
    "    compute_traditional_ood(output_dir, config['ood_datasets'], config['scoring_method'])\n",
    "    compute_in(output_dir, config['scoring_method'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config\", required=True, type=str, help=\"Path to config YML\")\n",
    "    parser.add_argument(\"--use-gpu\", action=\"store_true\", default=False, help=\"Enables GPU\")\n",
    "    parser.add_argument(\"--use-tqdm\", action=\"store_true\", default=False, help=\"Enables progress bar\")\n",
    "    args = parser.parse_args()\n",
    "    config = load_config_yml(args.config)\n",
    "    ood_eval(config, args.use_gpu, args.use_tqdm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
